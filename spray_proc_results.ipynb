{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from skimage.morphology import square, disk, dilation\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "\n",
    "from correlation import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top directory for processing results\n",
    "path_proc = 'proc_18_08_10\\\\'\n",
    "\n",
    "path_raw = path_proc +    'raw\\\\'\n",
    "path_input = path_proc +  'input\\\\'\n",
    "path_amp = path_proc +    'amp\\\\'\n",
    "path_flow_x = path_proc + 'flow_x\\\\'\n",
    "path_flow_y = path_proc + 'flow_y\\\\'\n",
    "path_corr = path_proc +   'corr\\\\'\n",
    "path_width = path_proc +  'width\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Velocity per pixel = 17.05 m/s\n",
      "Bernoulli limit 250.00 m/s = 14.67 pixels\n",
      "\n",
      "Velocity examples 6 pixel = 102.27 m/s\n",
      "Velocity examples 7 pixel = 119.32 m/s\n",
      "Velocity examples 10 pixel = 170.45 m/s\n"
     ]
    }
   ],
   "source": [
    "pixel_size = 3.0 # pixel size in micrometers\n",
    "bunch_period = 176  # 176 ns bunch separation period\n",
    "time_factor = bunch_period / 1000.0   # in microseconds\n",
    "vel_factor = pixel_size / time_factor\n",
    "\n",
    "\n",
    "sample_rate = 31.25 # sample rate = 32000 fps -> frame separation 31,2 microseconds\n",
    "\n",
    "bern_vel = 250.0\n",
    "\n",
    "# Number of shots for intergrated analysis\n",
    "shots_num = 5\n",
    "# Sequence length\n",
    "seq_length = 40\n",
    "\n",
    "# Radius of the pacth for overall statistics analysis\n",
    "rx = 40\n",
    "ry = 20\n",
    "\n",
    "print('Velocity per pixel = {0:.2f} m/s'.format(vel_factor))\n",
    "print('Bernoulli limit {0:.2f} m/s = {1:.2f} pixels'.format(bern_vel, bern_vel / vel_factor))\n",
    "print('')\n",
    "print('Velocity examples {0:d} pixel = {1:.2f} m/s'.format(6, 6*vel_factor))\n",
    "print('Velocity examples {0:d} pixel = {1:.2f} m/s'.format(7, 7*vel_factor))\n",
    "print('Velocity examples {0:d} pixel = {1:.2f} m/s'.format(10, 10*vel_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------\n",
    "#   Colors\n",
    "#---------------------------\n",
    "\n",
    "blue = (57 / 255.0, 106 / 255.0, 177 / 255.0)\n",
    "red = (204/ 255.0, 37/ 255.0, 41/ 255.0 )\n",
    "green = (62/ 255.0, 150/ 255.0, 81/ 255.0 )  \n",
    "grey = (128/ 255.0, 133/ 255.0, 133/ 255.0 )\n",
    "gold = (237/ 255.0, 218/ 255.0, 116/ 255.0 )\n",
    "\n",
    "#---------------------------\n",
    "#   Fonts\n",
    "#---------------------------\n",
    "\n",
    "title_font_size = 20\n",
    "label_font_size = 16\n",
    "ticks_font_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files_save_as_multitiff_stack(path, file_name):\n",
    "    files = sorted([f for f in listdir(path) if isfile(join(path, f))])\n",
    "    print('Number of images to convert:', len(files))\n",
    "\n",
    "    imlist = []\n",
    "    for f in files:\n",
    "        #im = np.array(Image.open(p + f))\n",
    "        #imlist.append(Image.fromarray(m))\n",
    "        with Image.open(path + f) as im:\n",
    "            np_im = np.array(im)\n",
    "            imlist.append(Image.fromarray(np_im))\n",
    "\n",
    "    imlist[0].save(file_name, save_all=True, append_images=imlist[1:])\n",
    "\n",
    "    print('OK')\n",
    "    \n",
    "    #return np.array(imlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------#\n",
    "# Time analysis              #\n",
    "#----------------------------#\n",
    "def time_analysis(images, cx, cy, rx, ry, y_pos=60, ax=None, region='all', show=False, filter_high=True, filter_zero=True, color='k'):\n",
    "    \n",
    "    if  not ax:\n",
    "        ax  = plt.subplot(111)\n",
    "\n",
    "    #def avg_nonzero(a): \n",
    "    #    return np.mean(a[a > 0])\n",
    "\n",
    "    all_shots_vel = []\n",
    "\n",
    "    #for s in range(1):    \n",
    "    for s in range(shots_num):\n",
    "        # Get sequence for the shot\n",
    "        seq = images[s*seq_length:(s+1)*seq_length]\n",
    "\n",
    "        mean_vel_values = []\n",
    "\n",
    "        #for i in range(1):\n",
    "        for i in range(seq_length): \n",
    "\n",
    "            im = seq[i][cy-ry:cy+ry,cx-rx:cx+rx]\n",
    "            #print(cy-r_2, cx-r_2)\n",
    "\n",
    "            # Filtering\n",
    "            # 1. Put away large velocity outliers\n",
    "            #filtered_amp = np.where(im < 10, im, 0)\n",
    "            if filter_high:\n",
    "                im = np.where(im < 10, im, 0)\n",
    "            # 2. Drop zero velocities from avareging\n",
    "            if filter_zero:\n",
    "                im = np.mean(im[im > 0])\n",
    "            #amp_nonzeros_mean = np.mean(filtered_amp[filtered_amp > 0])\n",
    "            if not (filter_high and filter_zero):\n",
    "                im = np.mean(im)\n",
    "                \n",
    "\n",
    "            # Convert to m/s\n",
    "            im = im*vel_factor\n",
    "            #amp_nonzeros_mean = amp_nonzeros_mean*vel_factor\n",
    "\n",
    "            mean_vel_values.append(im)\n",
    "            #mean_vel_values.append(amp_nonzeros_mean)\n",
    "\n",
    "        all_shots_vel.append(mean_vel_values)\n",
    "        #ax.plot(mean_vel_values, linewidth=1.0, alpha=0.3)\n",
    "\n",
    "    all_shots_mean = np.mean(np.array(all_shots_vel), axis=0)\n",
    "    ax.plot(all_shots_mean, linewidth=2.0, color=color, linestyle='dashed')\n",
    "\n",
    "    \n",
    "    ax.set_title('Velocity evolution, region: ' + region, size=title_font_size)\n",
    "    \n",
    "    x_lables = ['{:.1f}'.format(x) for x in np.arange(20, (20+seq_length)+1, 5)*sample_rate / 1000]\n",
    "    x_ticks = np.arange(0, seq_length+1, 5)\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_xticklabels(x_lables, fontsize = ticks_font_size)\n",
    "    \n",
    "    ax.set_ylabel('velocity, [m\\s]', size=label_font_size)\n",
    "    ax.set_xlabel('time from injection, [s]', size=label_font_size)\n",
    "\n",
    "\n",
    "    overall_mean = np.mean(all_shots_mean)\n",
    "    overall_std = np.std(all_shots_mean)\n",
    "\n",
    "    #print('Overall average in region {0:.2f} m/s'.format(overall_mean))\n",
    "    #print('Overall variation in region {0:.2f} m/s'.format(overall_std))\n",
    "    #print('Variation in percent {0:.1f} %'.format(overall_std / overall_mean * 100))\n",
    "    \n",
    "    ax.text(1, y_pos, 'Mean: {0:.2f} m/s'.format(overall_mean), fontsize=14, color=color)\n",
    "    ax.text(16, y_pos, 'STD: {0:.2f} m/s'.format(overall_std), fontsize=14, color=color)\n",
    "\n",
    "    ax.set_ylim(50,140)\n",
    "    ax.yaxis.set_tick_params(labelsize=label_font_size)\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "        \n",
    "    return overall_mean, overall_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_nonzero(a): \n",
    "    return np.mean(a[a > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total 33 datasets\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------\n",
    "# Read dataset list  \n",
    "#----------------------------------------\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open ('datasets\\\\datasets_list_all_18_09_10', 'rb') as fp:\n",
    "    dataset_list = pickle.load(fp)\n",
    "\n",
    "print('In total {0:d} datasets'.format(len(dataset_list)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "All Dataset for 19_08_10         \n",
    "---------------------------------\n",
    "          days geometry       view    op temp1 press temp2  region\n",
    "26   09.3-10.3    002_3  Ansicht 0  1bar  25°C   100  25°C    Z5Y0\n",
    "27   09.3-10.3    002_3  Ansicht 0  1bar  25°C   100  25°C  Z2.5Y0\n",
    "28   09.3-10.3    002_3  Ansicht 0  1bar  25°C   100  25°C    Z0Y0\n",
    "73   10.3-11.3    003_1  Ansicht 0  1bar  25°C   100  25°C    Z0Y0\n",
    "71   10.3-11.3    003_1  Ansicht 0  1bar  25°C   100  25°C    Z5Y0\n",
    "72   10.3-11.3    003_1  Ansicht 0  1bar  25°C   100  25°C  Z2.5Y0\n",
    "82   10.3-11.3    005_1  Ansicht ?  1bar  25°C   100  25°C    Z0Y0\n",
    "80   10.3-11.3    005_1  Ansicht ?  1bar  25°C   100  25°C    Z5Y0\n",
    "81   10.3-11.3    005_1  Ansicht ?  1bar  25°C   100  25°C  Z2.5Y0\n",
    "64   10.3-11.3    007_1  Ansicht ?  1bar  25°C   100  25°C    Z0Y0\n",
    "63   10.3-11.3    007_1  Ansicht ?  1bar  25°C   100  25°C  Z2.5Y0\n",
    "62   10.3-11.3    007_1  Ansicht ?  1bar  25°C   100  25°C    Z5Y0\n",
    "50   09.3-10.3    018_1  Ansicht 0  1bar  25°C   100  25°C    Z5Y0\n",
    "51   09.3-10.3    018_1  Ansicht 0  1bar  25°C   100  25°C  Z2.5Y0\n",
    "52   09.3-10.3    018_1  Ansicht 0  1bar  25°C   100  25°C    Z0Y0\n",
    "100  10.3-11.3    019_1  Ansicht 0  1bar  25°C   100  25°C    Z0Y0\n",
    "99   10.3-11.3    019_1  Ansicht 0  1bar  25°C   100  25°C  Z2.5Y0\n",
    "98   10.3-11.3    019_1  Ansicht 0  1bar  25°C   100  25°C    Z5Y0\n",
    "91   10.3-11.3    020_1  Ansicht 0  1bar  25°C   100  25°C    Z0Y0\n",
    "90   10.3-11.3    020_1  Ansicht 0  1bar  25°C   100  25°C  Z2.5Y0\n",
    "89   10.3-11.3    020_1  Ansicht 0  1bar  25°C   100  25°C    Z5Y0\n",
    "46   09.3-10.3    021_1  Ansicht 0  1bar  25°C   100  25°C    Z0Y0\n",
    "45   09.3-10.3    021_1  Ansicht 0  1bar  25°C   100  25°C  Z2.5Y0\n",
    "44   09.3-10.3    021_1  Ansicht 0  1bar  25°C   100  25°C    Z5Y0\n",
    "32   09.3-10.3    023_1  Ansicht 0  1bar  25°C   100  25°C    Z5Y0\n",
    "33   09.3-10.3    023_1  Ansicht 0  1bar  25°C   100  25°C  Z2.5Y0\n",
    "34   09.3-10.3    023_1  Ansicht 0  1bar  25°C   100  25°C    Z0Y0\n",
    "58   09.3-10.3    025_1  Ansicht 0  1bar  25°C   100  25°C    Z0Y0\n",
    "107  10.3-11.3    025_1  Ansicht 0  1bar  25°C   100  25°C    Z5Y0\n",
    "108  10.3-11.3    025_1  Ansicht 0  1bar  25°C   100  25°C  Z2.5Y0\n",
    "109  10.3-11.3    025_1  Ansicht 0  1bar  25°C   100  25°C    Z0Y0\n",
    "57   09.3-10.3    025_1  Ansicht 0  1bar  25°C   100  25°C  Z2.5Y0\n",
    "56   09.3-10.3    025_1  Ansicht 0  1bar  25°C   100  25°C    Z5Y0\n",
    "In total: 33\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# Select dataset for processing\n",
    "#----------------------------------------\n",
    "\n",
    "if False:\n",
    "    results_table = []\n",
    "    df = pd.DataFrame(columns=['Date', 'Dataset', 'Region', 'AvgVelA', 'StdVelA', 'AvgVelB', 'StdVelB', 'AvgVelC', 'StdVelC'])\n",
    "\n",
    "    #for dt in dataset_list[0:2]:\n",
    "    for dt in dataset_list:\n",
    "\n",
    "        date = dt[0]\n",
    "        dataset = dt[1]\n",
    "        region = dt[2]\n",
    "        path = dt[3]\n",
    "        #path = path.replace('\\\\', '/')\n",
    "        #path = path.replace('y:', '/mnt/LSDF')\n",
    "        path+='\\\\'\n",
    "        file_name = dt[4]\n",
    "\n",
    "\n",
    "        print('\\n--------------------')\n",
    "        print('Date:', date)\n",
    "        print('Dataset:', dataset)\n",
    "        print('Region:', region)\n",
    "        print('--------------------\\n')\n",
    "\n",
    "        if date == '09.3-10.3':\n",
    "            d = '09-10' \n",
    "\n",
    "        if date == '10.3-11.3':\n",
    "            d = '10-11'        \n",
    "\n",
    "        if date == '11.3-11.3':\n",
    "            d = '11-12' \n",
    "\n",
    "\n",
    "        #------------------------------\n",
    "        # Collect results\n",
    "        #------------------------------\n",
    "        results_path = path + path_proc + d + '_' + dataset + '_' + region\n",
    "\n",
    "        read_files_save_as_multitiff_stack(path + path_amp, results_path + '_amp_seq.tif')\n",
    "        read_files_save_as_multitiff_stack(path + path_corr, results_path + '_corr_seq.tif')\n",
    "\n",
    "\n",
    "        # Read dataset\n",
    "        max_read_images = 200  \n",
    "\n",
    "        #start = time()\n",
    "        images = read_tiff(results_path +'_amp_seq.tif', max_read_images)\n",
    "        corr   = read_tiff(results_path +'_corr_seq.tif', max_read_images)\n",
    "\n",
    "        #end = time()\n",
    "        #print ('Time elapsed: ', (end-start))\n",
    "\n",
    "        #------------------------------\n",
    "        # Start analysis\n",
    "        #------------------------------\n",
    "\n",
    "        print('Analysis...')\n",
    "\n",
    "        # Make masking\n",
    "        med = np.median(images, axis=0)  \n",
    "        thres = np.where(med > 5, 255.0, 0.0)\n",
    "        dilated = dilation(thres, disk(6))\n",
    "        mask = gaussian_filter(dilated, 3.5) \n",
    "        im_res = Image.fromarray(mask)\n",
    "        im_res.save(results_path + '_mask.tif')\n",
    "\n",
    "        # Mean velocity without any filtering\n",
    "        amp_mean = np.mean(images, axis=0)\n",
    "        im_res = Image.fromarray(amp_mean*vel_factor)\n",
    "        im_res.save(results_path + '_amp_mean_nofilter.tif')\n",
    "\n",
    "        # Filtering according to physical contraints\n",
    "\n",
    "        max_vel_in_pixels = 10\n",
    "        min_corr_value = 0.2\n",
    "\n",
    "        filtered_amp = np.where(images < max_vel_in_pixels, images, 0)\n",
    "        #filtered_amp = images # no filtering\n",
    "        #filtered_amp = np.where(np.abs(images) < 10, images, 0) # Filter y-components\n",
    "        filtered_corr = np.where(corr > min_corr_value, 1, 0)\n",
    "        filtered_amp = filtered_amp*filtered_corr\n",
    "\n",
    "        amp_filtered_mean = np.apply_along_axis(avg_nonzero, 0, filtered_amp)\n",
    "        im_res = Image.fromarray(amp_filtered_mean*vel_factor)\n",
    "        im_res.save(results_path + '_amp_mean_filter.tif')\n",
    "\n",
    "        measure_name = 'Mean filtered velocity'\n",
    "        measure_file = 'amp_mean_filter'\n",
    "\n",
    "        pano = amp_filtered_mean*vel_factor\n",
    "\n",
    "        amp_seq = images\n",
    "\n",
    "\n",
    "        # Setup figure\n",
    "        fig = plt.figure(1)\n",
    "\n",
    "        fig.set_size_inches(20/3 + 2, 14, forward=True)\n",
    "        plt.subplots_adjust(top=0.95, bottom=0.06, left=0.1, right=0.90, hspace=0.3 )\n",
    "\n",
    "        gs = gridspec.GridSpec(3, 1, height_ratios=[1.3,1,1])\n",
    "\n",
    "        #-------------------------------------------\n",
    "        # Figure 1: Velocity maps\n",
    "        #-------------------------------------------\n",
    "\n",
    "        # Setup figure\n",
    "        ax0 = plt.subplot(gs[0,:])\n",
    "\n",
    "        imx = ax0.imshow(pano, vmax=140, cmap='inferno')\n",
    "        ax0.set_title('Dataset: '+ dataset +', '+ measure_name, size=title_font_size, y=1.05)    \n",
    "        ax0.set_xlabel('distance, [mm]', size=label_font_size)\n",
    "        ax0.set_ylabel('distance, [mm]', size=label_font_size)\n",
    "\n",
    "        width = pano.shape[1]\n",
    "        x_lables = ['{:.1f}'.format(x) for x in np.arange(0, width+1, 100) /1000*pixel_size]\n",
    "        x_ticks = np.arange(0, width+1, 100)\n",
    "        ax0.set_xticks(x_ticks)\n",
    "        ax0.set_xticklabels(x_lables, fontsize = ticks_font_size)\n",
    "\n",
    "        height = pano.shape[0]\n",
    "        y_lables = ['{:.1f}'.format(x) for x in np.arange(0, height+1, 100) /1000*pixel_size]\n",
    "        y_ticks = np.arange(0, height+1, 100)\n",
    "        ax0.set_yticks(y_ticks)\n",
    "        ax0.set_yticklabels(y_lables)\n",
    "\n",
    "        ax0.yaxis.set_tick_params(labelsize=label_font_size)\n",
    "\n",
    "        axins0 = inset_axes(ax0,\n",
    "                           width=\"1.5%\",  # width = 10% of parent_bbox width\n",
    "                           height=\"100%\",  # height : 50%\n",
    "                           loc=3,\n",
    "                           bbox_to_anchor=(1.02, 0., 1, 1),\n",
    "                           bbox_transform=ax0.transAxes,\n",
    "                           borderpad=0                    \n",
    "                           )\n",
    "\n",
    "        # Separation lines between combined images\n",
    "\n",
    "        clb = plt.colorbar(imx, cax=axins0)\n",
    "        clb.ax.tick_params(labelsize=ticks_font_size)\n",
    "\n",
    "        step = int(350 / 2)\n",
    "\n",
    "        ax0.axvline(step*1,linewidth=2, color=blue, alpha=0.7)\n",
    "        ax0.axvline(step*2,linewidth=2, color=red, alpha=0.7)\n",
    "        ax0.axvline(step*3,linewidth=2, color=green, alpha=0.7)\n",
    "\n",
    "\n",
    "        # Create a Rectangle patch\n",
    "        rect1 = patches.Rectangle((step*1 - rx, height/2-ry),2*rx,2*ry,linewidth=1, linestyle='--',edgecolor=blue,facecolor='none', alpha=1.0)\n",
    "        ax0.add_patch(rect1)\n",
    "\n",
    "        rect2 = patches.Rectangle((step*2 - rx, height/2-ry),2*rx,2*ry,linewidth=1, linestyle='--',edgecolor=red,facecolor='none', alpha=1.0)\n",
    "        ax0.add_patch(rect2)\n",
    "\n",
    "        rect3 = patches.Rectangle((step*3 - rx, height/2-ry),2*rx,2*ry,linewidth=1, linestyle='--',edgecolor=green,facecolor='none', alpha=1.0)\n",
    "        ax0.add_patch(rect3)\n",
    "\n",
    "        ax0.grid(False)\n",
    "\n",
    "        #plt.show()\n",
    "        #fig.savefig(path + dataset + '_comb_' + measure[1] + '_map.png')\n",
    "\n",
    "\n",
    "        #-------------------------------------------\n",
    "        # Figure 2: Velocity profiles\n",
    "        #-------------------------------------------\n",
    "\n",
    "        plt.style.use('seaborn')\n",
    "\n",
    "        #fig.set_size_inches(25, 8, forward=True)\n",
    "        #plt.subplots_adjust(left=0.05, right=0.95, wspace=0.1)\n",
    "\n",
    "        data = pano\n",
    "\n",
    "        smooth_mask = 4\n",
    "\n",
    "        vel_min = 40\n",
    "        vel_max = 150\n",
    "\n",
    "\n",
    "        # Subplot 2\n",
    "        vel_profile_A = data[:,step*1]\n",
    "        vel_profile_B = data[:,step*2]\n",
    "        vel_profile_C = data[:,step*3]\n",
    "\n",
    "        np.savetxt(results_path + '_vel_profile_A.txt', vel_profile_A, fmt='%.5f')\n",
    "        np.savetxt(results_path + '_vel_profile_B.txt', vel_profile_B, fmt='%.5f')\n",
    "        np.savetxt(results_path + '_vel_profile_C.txt', vel_profile_C, fmt='%.5f')\n",
    "\n",
    "        ax1 = plt.subplot(gs[1,0])\n",
    "        ax1.set_title('spray region: '+region, size=title_font_size)\n",
    "        ax1.plot(smooth(vel_profile_A, smooth_mask, 'flat'), linewidth=1.5, color=blue)\n",
    "        ax1.plot(smooth(vel_profile_B, smooth_mask, 'flat'), linewidth=1.5, color=red)\n",
    "        ax1.plot(smooth(vel_profile_C, smooth_mask, 'flat'), linewidth=1.5, color=green)\n",
    "        ax1.set_ylim(vel_min, vel_max)\n",
    "        ax1.set_ylabel('velocity, [m\\s]', size=label_font_size)\n",
    "        ax1.set_xlabel('distance, [mm]', size=label_font_size)\n",
    "        ax1.set_xticks(y_ticks)\n",
    "        ax1.set_xticklabels(y_lables, fontsize = ticks_font_size)\n",
    "        ax1.yaxis.set_tick_params(labelsize=label_font_size)\n",
    "\n",
    "\n",
    "        #-------------------------------------------\n",
    "        # Figure 3: Velocity time evolution\n",
    "        #-------------------------------------------\n",
    "\n",
    "\n",
    "        f_high = True\n",
    "        f_zeros = True\n",
    "\n",
    "\n",
    "        # Subplot 2\n",
    "        ax4 = plt.subplot(gs[2,0])\n",
    "        avg_vel_A, std_vel_A = time_analysis(amp_seq, int(width/4), int(height/2), rx, ry, 73, ax4, region=region, filter_high=f_high, filter_zero=f_zeros, show=False, color=blue)\n",
    "        avg_vel_B, std_vel_B = time_analysis(amp_seq, int(width/2), int(height/2), rx, ry, 63, ax4, region=region, filter_high=f_high, filter_zero=f_zeros, show=False, color=red)\n",
    "        avg_vel_C, std_vel_C = time_analysis(amp_seq, int(3*width/4), int(height/2), rx, ry, 53, ax4, region=region, filter_high=f_high, filter_zero=f_zeros, show=False, color=green)\n",
    "\n",
    "\n",
    "        all_results_path = 'y:\\\\projects\\\\pn-reduction\\\\2018_03_esrf_mi1325\\\\Phantom\\\\Glasduese\\\\analysis_all_results\\\\'\n",
    "\n",
    "        #plt.show()\n",
    "        fig.savefig(results_path + '_comb_'+ measure_file +'_fig.png')\n",
    "        fig.savefig(all_results_path + region + '\\\\' + d + '_' + dataset + '_' + region + '_comb_'+ measure_file +'_fig.png')\n",
    "\n",
    "\n",
    "        #-------------------------------------------\n",
    "        # Summary results table\n",
    "        #-------------------------------------------\n",
    "\n",
    "        res = [date, dataset, region, avg_vel_A, std_vel_A, avg_vel_B, std_vel_B, avg_vel_C, std_vel_C]\n",
    "\n",
    "        df.loc[len(df)] = res\n",
    "\n",
    "        print('OK')\n",
    "        #results_table.append(res)\n",
    "\n",
    "        #plt.draw()\n",
    "        #plt.show()\n",
    "\n",
    "\n",
    "    df.to_excel(all_results_path + 'results_table.xlsx', sheet_name='Results')\n",
    "\n",
    "    #file = open(all_results_path + 'results_table.txt', 'w')\n",
    "    #file.writelines([\"%s\\n\" % item  for item in results_table])\n",
    "    #file.close()\n",
    "\n",
    "    #np.savetxt(all_results_path + 'results_table.txt', results_table, fmt='%.2f')\n",
    "\n",
    "    print('Finished!')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
